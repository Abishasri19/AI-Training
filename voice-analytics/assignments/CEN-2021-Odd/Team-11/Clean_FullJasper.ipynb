{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Clean_FullJasper.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jh2ruFwWBECI"},"source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://drive.google.com/file/d/1zU3Cja1abmD54CTluirBnr5I5Sl8GYPx/view?usp=sharing)"]},{"cell_type":"markdown","metadata":{"id":"W64kfNOxl5tv"},"source":["Since the model is devoleped using tf version 1 we are installing the version tf.1.xx"]},{"cell_type":"code","metadata":{"id":"8jepeNIU0X1Z"},"source":["!pip install tensorflow-gpu==1.15.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eqO3Cm6DyhKi","outputId":"aac8783e-5db1-4fda-fa27-f20cf4372e78"},"source":["import tensorflow.compat.v1 as tf\n","tf.disable_v2_behavior()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","non-resource variables are not supported in the long term\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lOtacbfVro2K","outputId":"82540437-f210-4eed-a5f3-64fee1993a06"},"source":["#!gdown --id 1HH23gWovcBwRQTh0kOwYIl55I-P0LtIY\n","# !gdown --id 1En86LcxRw701XIXOy31wHx4NTUTluYzY\n","!gdown --id 1oEVk04zVpQkvW9YdgRQ9k7tuMPvbEbLq"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1oEVk04zVpQkvW9YdgRQ9k7tuMPvbEbLq\n","To: /content/FullData.zip\n","100% 508M/508M [00:07<00:00, 70.9MB/s]\n"]}]},{"cell_type":"code","metadata":{"id":"4OAYywPHApuz","colab":{"base_uri":"https://localhost:8080/"},"outputId":"6a9f77d8-da6f-4893-e537-a4f19c84a0e9"},"source":["import os\n","from os.path import exists, join, basename, splitext\n","\n","git_repo_url = 'https://github.com/NVIDIA/OpenSeq2Seq.git'\n","project_name = splitext(basename(git_repo_url))[0]\n","if not exists(project_name):\n","  # clone and install dependencies\n","  !git clone -q --depth 1 {git_repo_url}\n","  !pip uninstall -y -q pymc3\n","  !pip install --upgrade joblib\n","  !pip install -q youtube-dl librosa python_speech_features sentencepiece\n","  \n","  # create eval config\n","  !cp {project_name}/example_configs/speech2text/jasper10x5_LibriSpeech_nvgrad.py {project_name}/conf.py\n","  !sed -i -e 's/\\/data\\/librispeech\\/librivox-test-clean/test/' {project_name}/conf.py\n","  !echo 'backend = \"librosa\"' >> {project_name}/conf.py \n","  # !echo \"wav_filename, wav_filesize, transcript\" > {project_name}/test.csv\n","  # !echo \"test.wav, UNUSED, UNUSED\" >> {project_name}/test.csv\n","  \n","import sys\n","sys.path.append(project_name)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (1.1.0)\n","\u001b[K     |████████████████████████████████| 1.9 MB 5.3 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 37.7 MB/s \n","\u001b[?25h  Building wheel for python-speech-features (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","metadata":{"id":"NpHyrSlZtKcw"},"source":["!unzip /content/FullData.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"P49WriI8TmZr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_testu = pd.read_csv(\"/content/FullData/test.csv\")"],"metadata":{"id":"AShTedDIVO-T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_testu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"h06jEUzXVcUI","outputId":"db2cf82f-fdee-4bc8-c77e-e8d3aa870e3e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>wav_filename</th>\n","      <th>wav_filesize</th>\n","      <th>transcript</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>file_00.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>file_01.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>file_010.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>file_0100.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>file_01000.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2615</th>\n","      <td>file_0995.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","    <tr>\n","      <th>2616</th>\n","      <td>file_0996.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","    <tr>\n","      <th>2617</th>\n","      <td>file_0997.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","    <tr>\n","      <th>2618</th>\n","      <td>file_0998.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","    <tr>\n","      <th>2619</th>\n","      <td>file_0999.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2620 rows × 3 columns</p>\n","</div>"],"text/plain":["        wav_filename wav_filesize transcript\n","0        file_00.wav       UNUSED     UNUSED\n","1        file_01.wav       UNUSED     UNUSED\n","2       file_010.wav       UNUSED     UNUSED\n","3      file_0100.wav       UNUSED     UNUSED\n","4     file_01000.wav       UNUSED     UNUSED\n","...              ...          ...        ...\n","2615   file_0995.wav       UNUSED     UNUSED\n","2616   file_0996.wav       UNUSED     UNUSED\n","2617   file_0997.wav       UNUSED     UNUSED\n","2618   file_0998.wav       UNUSED     UNUSED\n","2619   file_0999.wav       UNUSED     UNUSED\n","\n","[2620 rows x 3 columns]"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["for i in range(df_testu.shape[0]):\n","  path = \"FullData/audio/\"\n","  name = df_testu[\"wav_filename\"][i]\n","  new_path = os.path.join(path, name)\n","  df_testu[\"wav_filename\"][i] = new_path"],"metadata":{"id":"c9Bm1A1ISNku"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_testu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"R3Efz9mRUaAA","outputId":"1c7d4bbb-9a04-4c78-a50e-c20108c4fbc6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>wav_filename</th>\n","      <th>wav_filesize</th>\n","      <th>transcript</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>FullData/audio/file_00.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>FullData/audio/file_01.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>FullData/audio/file_010.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>FullData/audio/file_0100.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>FullData/audio/file_01000.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2615</th>\n","      <td>FullData/audio/file_0995.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","    <tr>\n","      <th>2616</th>\n","      <td>FullData/audio/file_0996.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","    <tr>\n","      <th>2617</th>\n","      <td>FullData/audio/file_0997.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","    <tr>\n","      <th>2618</th>\n","      <td>FullData/audio/file_0998.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","    <tr>\n","      <th>2619</th>\n","      <td>FullData/audio/file_0999.wav</td>\n","      <td>UNUSED</td>\n","      <td>UNUSED</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2620 rows × 3 columns</p>\n","</div>"],"text/plain":["                       wav_filename wav_filesize transcript\n","0        FullData/audio/file_00.wav       UNUSED     UNUSED\n","1        FullData/audio/file_01.wav       UNUSED     UNUSED\n","2       FullData/audio/file_010.wav       UNUSED     UNUSED\n","3      FullData/audio/file_0100.wav       UNUSED     UNUSED\n","4     FullData/audio/file_01000.wav       UNUSED     UNUSED\n","...                             ...          ...        ...\n","2615   FullData/audio/file_0995.wav       UNUSED     UNUSED\n","2616   FullData/audio/file_0996.wav       UNUSED     UNUSED\n","2617   FullData/audio/file_0997.wav       UNUSED     UNUSED\n","2618   FullData/audio/file_0998.wav       UNUSED     UNUSED\n","2619   FullData/audio/file_0999.wav       UNUSED     UNUSED\n","\n","[2620 rows x 3 columns]"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["df_testu.to_csv(\"/content/OpenSeq2Seq/test.csv\")"],"metadata":{"id":"Igmfox9VUxaU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp -r /content/FullData /content/OpenSeq2Seq"],"metadata":{"id":"6YAdWHVcVkhQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E_4ycaB7aRd4"},"source":["## Download pre-trained Model"]},{"cell_type":"code","metadata":{"id":"P7eRRjlYaV1s","colab":{"base_uri":"https://localhost:8080/"},"outputId":"68c2d969-d4aa-4664-d22d-b58836704f97"},"source":["def download_from_google_drive(file_id, file_name):\n","  # download a file from the Google Drive link\n","  !rm -f ./cookie\n","  !curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id={file_id}\" > /dev/null\n","  confirm_text = !awk '/download/ {print $NF}' ./cookie\n","  confirm_text = confirm_text[0]\n","  !curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm={confirm_text}&id={file_id}\" -o {file_name}\n","  \n","if not exists(join(project_name, 'w2l_log_folder')):\n","  download_from_google_drive('1gzGT8HoVNKY1i5HNQTKaSoCu7JHV4siR', 'jasper_10x5_dr_sp_nvgrad.zip')\n","  !unzip jasper_10x5_dr_sp_nvgrad.zip\n","  !mv checkpoint {project_name}/jasper_log_folder"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   408    0   408    0     0   2372      0 --:--:-- --:--:-- --:--:--  2372\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n","100 2960M  100 2960M    0     0  73.7M      0  0:00:40  0:00:40 --:--:-- 41.0M\n","Archive:  jasper_10x5_dr_sp_nvgrad.zip\n","   creating: checkpoint/\n","  inflating: checkpoint/checkpoint   \n","  inflating: checkpoint/model.ckpt-439200.data-00000-of-00001  \n","  inflating: checkpoint/model.ckpt-439200.index  \n","  inflating: checkpoint/model.ckpt-439200.meta  \n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EUmQiNBk12Dq","outputId":"2bf43fbb-a4d0-49ca-ee2c-b730813008c9"},"source":["!cd {project_name} && python run.py --config_file conf.py --mode=infer --infer_output_file=LMFull.txt --use_horovod=False --num_gpus=1 --batch_size_per_gpu 1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/utils/hooks.py:15: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/utils/helpers.py:181: The name tf.train.SessionCreator is deprecated. Please use tf.compat.v1.train.SessionCreator instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/utils/helpers.py:240: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/utils/helpers.py:285: The name tf.train.SessionManager is deprecated. Please use tf.compat.v1.train.SessionManager instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/optimizers/mp_wrapper.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/optimizers/optimizers.py:37: The name tf.train.AdagradOptimizer is deprecated. Please use tf.compat.v1.train.AdagradOptimizer instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/optimizers/optimizers.py:38: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/optimizers/optimizers.py:39: The name tf.train.FtrlOptimizer is deprecated. Please use tf.compat.v1.train.FtrlOptimizer instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/optimizers/optimizers.py:40: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/optimizers/optimizers.py:41: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/optimizers/optimizers.py:42: The name tf.train.GradientDescentOptimizer is deprecated. Please use tf.compat.v1.train.GradientDescentOptimizer instead.\n","\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/parts/transformer/attention_layer.py:24: The name tf.layers.Layer is deprecated. Please use tf.compat.v1.layers.Layer instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/parts/cnns/tcn.py:8: The name tf.layers.Conv1D is deprecated. Please use tf.compat.v1.layers.Conv1D instead.\n","\n","*** Restoring from the latest checkpoint\n","*** Loading model from jasper_log_folder/model.ckpt-439200\n","*** Inference config:\n","{'batch_size_per_gpu': 1,\n"," 'data_layer': <class 'open_seq2seq.data.speech2text.speech2text.Speech2TextDataLayer'>,\n"," 'data_layer_params': {'backend': 'librosa',\n","                       'dataset_files': ['test.csv'],\n","                       'dither': 1e-05,\n","                       'input_type': 'logfbank',\n","                       'norm_per_feature': True,\n","                       'num_audio_features': 64,\n","                       'pad_to': 16,\n","                       'precompute_mel_basis': True,\n","                       'sample_freq': 16000,\n","                       'shuffle': False,\n","                       'vocab_file': 'open_seq2seq/test_utils/toy_speech_data/vocab.txt',\n","                       'window': 'hanning'},\n"," 'decoder': <class 'open_seq2seq.decoders.fc_decoders.FullyConnectedCTCDecoder'>,\n"," 'decoder_params': {'infer_logits_to_pickle': False,\n","                    'initializer': <function xavier_initializer at 0x7f28ad4bbf80>,\n","                    'use_language_model': False},\n"," 'dtype': 'mixed',\n"," 'encoder': <class 'open_seq2seq.encoders.tdnn_encoder.TDNNEncoder'>,\n"," 'encoder_params': {'activation_fn': <function relu at 0x7f28df768170>,\n","                    'convnet_layers': [{'dilation': [1],\n","                                        'dropout_keep_prob': 0.8,\n","                                        'kernel_size': [11],\n","                                        'num_channels': 256,\n","                                        'padding': 'SAME',\n","                                        'repeat': 1,\n","                                        'stride': [2],\n","                                        'type': 'conv1d'},\n","                                       {'dilation': [1],\n","                                        'dropout_keep_prob': 0.8,\n","                                        'kernel_size': [11],\n","                                        'num_channels': 256,\n","                                        'padding': 'SAME',\n","                                        'repeat': 5,\n","                                        'residual': True,\n","                                        'residual_dense': True,\n","                                        'stride': [1],\n","                                        'type': 'conv1d'},\n","                                       {'dilation': [1],\n","                                        'dropout_keep_prob': 0.8,\n","                                        'kernel_size': [11],\n","                                        'num_channels': 256,\n","                                        'padding': 'SAME',\n","                                        'repeat': 5,\n","                                        'residual': True,\n","                                        'residual_dense': True,\n","                                        'stride': [1],\n","                                        'type': 'conv1d'},\n","                                       {'dilation': [1],\n","                                        'dropout_keep_prob': 0.8,\n","                                        'kernel_size': [13],\n","                                        'num_channels': 384,\n","                                        'padding': 'SAME',\n","                                        'repeat': 5,\n","                                        'residual': True,\n","                                        'residual_dense': True,\n","                                        'stride': [1],\n","                                        'type': 'conv1d'},\n","                                       {'dilation': [1],\n","                                        'dropout_keep_prob': 0.8,\n","                                        'kernel_size': [13],\n","                                        'num_channels': 384,\n","                                        'padding': 'SAME',\n","                                        'repeat': 5,\n","                                        'residual': True,\n","                                        'residual_dense': True,\n","                                        'stride': [1],\n","                                        'type': 'conv1d'},\n","                                       {'dilation': [1],\n","                                        'dropout_keep_prob': 0.8,\n","                                        'kernel_size': [17],\n","                                        'num_channels': 512,\n","                                        'padding': 'SAME',\n","                                        'repeat': 5,\n","                                        'residual': True,\n","                                        'residual_dense': True,\n","                                        'stride': [1],\n","                                        'type': 'conv1d'},\n","                                       {'dilation': [1],\n","                                        'dropout_keep_prob': 0.8,\n","                                        'kernel_size': [17],\n","                                        'num_channels': 512,\n","                                        'padding': 'SAME',\n","                                        'repeat': 5,\n","                                        'residual': True,\n","                                        'residual_dense': True,\n","                                        'stride': [1],\n","                                        'type': 'conv1d'},\n","                                       {'dilation': [1],\n","                                        'dropout_keep_prob': 0.7,\n","                                        'kernel_size': [21],\n","                                        'num_channels': 640,\n","                                        'padding': 'SAME',\n","                                        'repeat': 5,\n","                                        'residual': True,\n","                                        'residual_dense': True,\n","                                        'stride': [1],\n","                                        'type': 'conv1d'},\n","                                       {'dilation': [1],\n","                                        'dropout_keep_prob': 0.7,\n","                                        'kernel_size': [21],\n","                                        'num_channels': 640,\n","                                        'padding': 'SAME',\n","                                        'repeat': 5,\n","                                        'residual': True,\n","                                        'residual_dense': True,\n","                                        'stride': [1],\n","                                        'type': 'conv1d'},\n","                                       {'dilation': [1],\n","                                        'dropout_keep_prob': 0.7,\n","                                        'kernel_size': [25],\n","                                        'num_channels': 768,\n","                                        'padding': 'SAME',\n","                                        'repeat': 5,\n","                                        'residual': True,\n","                                        'residual_dense': True,\n","                                        'stride': [1],\n","                                        'type': 'conv1d'},\n","                                       {'dilation': [1],\n","                                        'dropout_keep_prob': 0.7,\n","                                        'kernel_size': [25],\n","                                        'num_channels': 768,\n","                                        'padding': 'SAME',\n","                                        'repeat': 5,\n","                                        'residual': True,\n","                                        'residual_dense': True,\n","                                        'stride': [1],\n","                                        'type': 'conv1d'},\n","                                       {'dilation': [2],\n","                                        'dropout_keep_prob': 0.6,\n","                                        'kernel_size': [29],\n","                                        'num_channels': 896,\n","                                        'padding': 'SAME',\n","                                        'repeat': 1,\n","                                        'stride': [1],\n","                                        'type': 'conv1d'},\n","                                       {'dilation': [1],\n","                                        'dropout_keep_prob': 0.6,\n","                                        'kernel_size': [1],\n","                                        'num_channels': 1024,\n","                                        'padding': 'SAME',\n","                                        'repeat': 1,\n","                                        'stride': [1],\n","                                        'type': 'conv1d'}],\n","                    'data_format': 'channels_last',\n","                    'dropout_keep_prob': 0.7,\n","                    'initializer': <function xavier_initializer at 0x7f28ad4bbf80>,\n","                    'initializer_params': {'uniform': False},\n","                    'normalization': 'batch_norm',\n","                    'use_conv_mask': True},\n"," 'eval_steps': 2200,\n"," 'iter_size': 1,\n"," 'larc_params': {'larc_eta': 0.001},\n"," 'load_model': '',\n"," 'logdir': 'jasper_log_folder',\n"," 'loss': <class 'open_seq2seq.losses.ctc_loss.CTCLoss'>,\n"," 'loss_params': {},\n"," 'loss_scaling': 'Backoff',\n"," 'lr_policy': <function poly_decay at 0x7f28a6dc1200>,\n"," 'lr_policy_params': {'learning_rate': 0.02, 'min_lr': 1e-05, 'power': 2.0},\n"," 'num_checkpoints': 2,\n"," 'num_epochs': 400,\n"," 'num_gpus': 1,\n"," 'optimizer': <class 'open_seq2seq.optimizers.novograd.NovoGrad'>,\n"," 'optimizer_params': {'beta1': 0.95,\n","                      'beta2': 0.98,\n","                      'epsilon': 1e-08,\n","                      'grad_averaging': False,\n","                      'weight_decay': 0.001},\n"," 'print_loss_steps': 10,\n"," 'print_samples_steps': 2200,\n"," 'random_seed': 0,\n"," 'save_checkpoint_steps': 1100,\n"," 'save_summaries_steps': 100,\n"," 'summaries': ['learning_rate',\n","               'variables',\n","               'gradients',\n","               'larc_summaries',\n","               'variable_norm',\n","               'gradient_norm',\n","               'global_gradient_norm'],\n"," 'use_horovod': False,\n"," 'use_xla_jit': False}\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/models/model.py:312: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/models/model.py:390: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/models/model.py:391: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n","\n","*** Building graph on GPU:0\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/data/speech2text/speech2text.py:268: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","WARNING:tensorflow:Entity <function Speech2TextDataLayer.build_graph.<locals>.<lambda> at 0x7f28a6bcc050> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <function Speech2TextDataLayer.build_graph.<locals>.<lambda> at 0x7f28a6bcc050>, which Python reported as:\n","            lambda x, x_len, idx, duration:\n","\n","If this is a lambda function, the error may be avoided by creating the lambda in a standalone statement.\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/data/speech2text/speech2text.py:296: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/data/speech2text/speech2text.py:316: The name tf.mod is deprecated. Please use tf.math.mod instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/parts/cnns/conv_blocks.py:205: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.keras.layers.Conv1D` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/convolutional.py:218: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/parts/cnns/conv_blocks.py:223: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/encoders/tdnn_encoder.py:255: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/decoders/fc_decoders.py:139: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","*** Inference Mode. Loss part of graph isn't built.\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/utils/funcs.py:226: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/utils/funcs.py:227: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/utils/funcs.py:233: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2021-12-14 19:12:31.604825: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n","2021-12-14 19:12:31.710589: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n","2021-12-14 19:12:31.711196: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558bebcdf880 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2021-12-14 19:12:31.711243: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2021-12-14 19:12:31.716933: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2021-12-14 19:12:31.961079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-14 19:12:31.962071: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558bebcde1c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2021-12-14 19:12:31.962113: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n","2021-12-14 19:12:31.965713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-14 19:12:31.966522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n","pciBusID: 0000:00:04.0\n","2021-12-14 19:12:32.051387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2021-12-14 19:12:32.304232: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2021-12-14 19:12:32.385758: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\n","2021-12-14 19:12:32.439643: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\n","2021-12-14 19:12:32.642697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\n","2021-12-14 19:12:32.767472: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\n","2021-12-14 19:12:33.185557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2021-12-14 19:12:33.185800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-14 19:12:33.186628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-14 19:12:33.187285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2021-12-14 19:12:33.190458: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\n","2021-12-14 19:12:33.192496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2021-12-14 19:12:33.192551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2021-12-14 19:12:33.192575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2021-12-14 19:12:33.197167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-14 19:12:33.198021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-12-14 19:12:33.198794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/utils/helpers.py:482: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/utils/helpers.py:485: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/utils/helpers.py:487: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From /content/OpenSeq2Seq/open_seq2seq/utils/helpers.py:487: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/util/decorator_utils.py:145: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n","2021-12-14 19:12:33.353223: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 17203200 exceeds 10% of system memory.\n","2021-12-14 19:12:33.369027: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 17203200 exceeds 10% of system memory.\n","2021-12-14 19:12:33.381676: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 17203200 exceeds 10% of system memory.\n","2021-12-14 19:12:33.400801: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 17203200 exceeds 10% of system memory.\n","2021-12-14 19:12:33.413651: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 17203200 exceeds 10% of system memory.\n","2021-12-14 19:12:40.483927: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\n","2021-12-14 19:12:41.589434: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","*** Processed 1/2620 batches\n","*** Processed 262/2620 batches\n","*** Processed 524/2620 batches\n","*** Processed 786/2620 batches\n","*** Processed 1048/2620 batches\n","*** Processed 1310/2620 batches\n","*** Processed 1572/2620 batches\n","*** Processed 1834/2620 batches\n","*** Processed 2096/2620 batches\n","*** Processed 2358/2620 batches\n","*** Processed 2620/2620 batches\n","*** Processed 2620/2620 batches\n","*** Avg time per step: 0.364s\n","*** Avg objects per second: 2043.365\n","*** Finished inference\n"]}]},{"cell_type":"code","metadata":{"id":"r2JqicMmExXl"},"source":["!cat '/content/OpenSeq2Seq/LMFull.txt'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H_imo13Y8aGy","outputId":"ee75298c-a58e-4aa7-ed32-d60c55a818fd"},"source":["!pip install jiwer"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting jiwer\n","  Downloading jiwer-2.3.0-py3-none-any.whl (15 kB)\n","Collecting python-Levenshtein==0.12.2\n","  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 2.9 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein==0.12.2->jiwer) (57.4.0)\n","Building wheels for collected packages: python-Levenshtein\n","  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149873 sha256=9838bb7ef9492d72bd8d0fdc5cbcfd00ffd0072daac38be2c59e052a0df1ac47\n","  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n","Successfully built python-Levenshtein\n","Installing collected packages: python-Levenshtein, jiwer\n","Successfully installed jiwer-2.3.0 python-Levenshtein-0.12.2\n"]}]},{"cell_type":"code","metadata":{"id":"VtMkcB3NKWdR"},"source":["file2 = open(\"/content/OpenSeq2Seq/LMFull.txt\",\"r+\") \n","file2.readline(0)\n","X2 = file2.readlines()\n","file2.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bwZxPvLHKbCc"},"source":["NoLMPredictions = list(X2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(NoLMPredictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AUTHvEyod2L4","outputId":"844d87e0-0e36-460d-a6af-9c92be47d24c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2621"]},"metadata":{},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"g-7-h6ik_8px"},"source":["import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wc1XlQGM-vko"},"source":["actual_text = pd.read_csv('/content/OpenSeq2Seq/FullData/text.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install jiwer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kSLvz6t-b2h5","outputId":"18f754e4-a501-4d4c-8b5d-5d659f6ea607"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting jiwer\n","  Downloading jiwer-2.3.0-py3-none-any.whl (15 kB)\n","Collecting python-Levenshtein==0.12.2\n","  Downloading python-Levenshtein-0.12.2.tar.gz (50 kB)\n","\u001b[?25l\r\u001b[K     |██████▌                         | 10 kB 22.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 20 kB 20.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 30 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 40 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 50 kB 3.8 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein==0.12.2->jiwer) (57.4.0)\n","Building wheels for collected packages: python-Levenshtein\n","  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149861 sha256=1e81e8e179e4e1279d09cea900d35fb2e67a8e400c7afcf63ac2358ffcb0a751\n","  Stored in directory: /root/.cache/pip/wheels/05/5f/ca/7c4367734892581bb5ff896f15027a932c551080b2abd3e00d\n","Successfully built python-Levenshtein\n","Installing collected packages: python-Levenshtein, jiwer\n","Successfully installed jiwer-2.3.0 python-Levenshtein-0.12.2\n"]}]},{"cell_type":"code","metadata":{"id":"012RfNVM1WFt"},"source":["from jiwer import wer"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["NoLMPredictions[0:5]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yDQtJ9IteC9o","outputId":"338599a5-e99d-4571-9886-8873d200acaf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['wav_filename,predicted_transcript\\n',\n"," 'FullData/audio/file_00.wav,he hoped there would be stew for dinner turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick peppered flower fattened sauce\\n',\n"," 'FullData/audio/file_01.wav,stuff it into you his belly counselled him\\n',\n"," 'FullData/audio/file_010.wav,well now ennis i declare you have a head and so has my stick\\n',\n"," 'FullData/audio/file_0100.wav,in both these high mythical subjects the surrounding nature though suffering is still dignified and beautiful\\n']"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["NoLMPredictions.remove(\"wav_filename,predicted_transcript\\n\")"],"metadata":{"id":"IWxE8Is6eQ-8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["NoLMPredictions"],"metadata":{"id":"x59QZolQegCd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["NoLMPredictions[0][len(NoLMPredictions[0].split(\",\")[0])+1:-1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"wJSBh4dWezfi","outputId":"90e70dfa-3e68-42c0-a594-66d7cbc42aff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'he hoped there would be stew for dinner turnips and carrots and bruised potatoes and fat mutton pieces to be ladled out in thick peppered flower fattened sauce'"]},"metadata":{},"execution_count":77}]},{"cell_type":"code","metadata":{"id":"v8modohy_Uhf"},"source":["NoLMprediction_list = []\n","for i in range(len(NoLMPredictions)):\n","  temp = NoLMPredictions[i][len(NoLMPredictions[i].split(\",\")[0])+1:-1]\n","  NoLMprediction_list.append(temp)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kyedJdVzK8Dr"},"source":["NoLMprediction_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dMVCMZqkK97x"},"source":["NoLMwer_list = []\n","for i in range(len(NoLMPredictions)):\n","  indexu = int(os.path.basename(NoLMPredictions[i].split(\",\")[0])[6:-4])\n","  wer_temp2 = wer(actual_text['text'][indexu].lower(),NoLMprediction_list[i])\n","  NoLMwer_list.append(wer_temp2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x0PU81UeLKFi"},"source":["NoLMwer_list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g46ZSmNyLM8p","outputId":"75ea3a5b-6ec9-404b-84f9-9f55243a7db5"},"source":["Avg_wer = sum(NoLMwer_list) / len(NoLMwer_list)\n","Avg_wer"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.04387671045989565"]},"metadata":{},"execution_count":145}]},{"cell_type":"code","metadata":{"id":"Fq85AmXqBXvR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QDUPYlrYBXyO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SkFpussrLOzh"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zwDJ0HLVBWRs"},"source":[""],"execution_count":null,"outputs":[]}]}